
Edit the Makefile and define your mpi compile script (MPICC=).

Type

> make

and two programs will be made: one called MasterSlave and one MPIprobe.

To run the MPI program it is assumed that you also can use a job scheduler (like PBS) which can schedule MPI jobs on the cluster. In the script jobpbs.scr you can change the number of nodes in the line

#PBS -l nodes=1

submit your job to the queue system with

> qsub jobpbs.scr

and check if it is running with qstat. The output you will get looks like:

-bash-3.00$ qstat
Job id           Name             User             Time Use S Queue
---------------- ---------------- ---------------- -------- - -----
193916.linux     MPI_PI           jan                     0 R default    


The file MPI_PI.e193916 (where the number if the Job id) contains the results which where written to screen.

-bash-3.00$ more MPI_PI.e193916
8
::::::::::::::
/var/opt/torque-1.2.0p5/aux/193916.linux.ak.com
::::::::::::::
ak007
ak006
ak005
ak004
ak003
ak002
ak001
linux.cluster01.tnw
/home/jan/MPI_pi
The number of intervals = 1000000000
Running with 8 MPI processes. 
walltime=3.277904e+00
pi is approximately 3.1415926535897931, Error is 0.0000000000000000
------------clean up------------
running pbs epilogue script
killing processes of user jan on the batch nodes
Doing node ak007
Doing node ak006
Doing node ak005
Doing node ak004
Doing node ak003
Doing node ak002
Doing node ak001
Doing node linux.cluster01.tnw
Done

If you use mpich2 you should use another job script for your jobs and use mpiexec in stead of mpirun to run the MPI job. The example script jobmpich2.scr show an example how to use mpich2.


The program does not do any calculation and only uses the master-slave algorithm to distribute the amount of work. Try to change the workload of the workers by using different sleep() commands for each worker. 
